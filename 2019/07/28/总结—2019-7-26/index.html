<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
    

    

    



    <meta charset="utf-8">
    
    
    
    
    <title>总结—2019/7/27 | Alephn&#39;s Blog | Stay hungry, stay foolish</title>
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
    
    <meta name="theme-color" content="#3F51B5">
    
    
    <meta name="keywords" content="machien learning">
    <meta name="description" content="总结-2019/7/27下面主要对7-22～7-26这几天学习的一些知识进行一次回顾">
<meta name="keywords" content="machien learning">
<meta property="og:type" content="article">
<meta property="og:title" content="总结—2019&#x2F;7&#x2F;27">
<meta property="og:url" content="http://yoursite.com/2019/07/28/总结—2019-7-26/index.html">
<meta property="og:site_name" content="Alephn&#39;s Blog">
<meta property="og:description" content="总结-2019/7/27下面主要对7-22～7-26这几天学习的一些知识进行一次回顾">
<meta property="og:locale" content="default">
<meta property="og:image" content="http://yoursite.com/2019/07/28/总结—2019-7-26/network.png">
<meta property="og:image" content="http://yoursite.com/2019/07/28/总结—2019-7-26/overfitting.png">
<meta property="og:image" content="http://yoursite.com/2019/07/28/总结—2019-7-26/loss.png">
<meta property="og:updated_time" content="2019-07-28T10:03:43.086Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="总结—2019&#x2F;7&#x2F;27">
<meta name="twitter:description" content="总结-2019/7/27下面主要对7-22～7-26这几天学习的一些知识进行一次回顾">
<meta name="twitter:image" content="http://yoursite.com/2019/07/28/总结—2019-7-26/network.png">
    
        <link rel="alternate" type="application/atom+xml" title="Alephn&#39;s Blog" href="/atom.xml">
    
    <link rel="shortcut icon" href="/favicon.ico">
    <link rel="stylesheet" href="//unpkg.com/hexo-theme-material-indigo@latest/css/style.css">
    <script>window.lazyScripts=[]</script>

    <!-- custom head -->
    

</head>

<body>
    <div id="loading" class="active"></div>

    <aside id="menu" class="hide">
  <div class="inner flex-row-vertical">
    <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menu-off">
        <i class="icon icon-lg icon-close"></i>
    </a>
    <div class="brand-wrap" style="background-image:url(/img/brand.jpeg)">
      <div class="brand">
        <a href="/" class="avatar waves-effect waves-circle waves-light">
          <img src="/img/avatar.jpg">
        </a>
        <hgroup class="introduce">
          <h5 class="nickname">Alephn</h5>
          <a href="mailto:wz520@mail.ustc.edu.cn" title="wz520@mail.ustc.edu.cn" class="mail">wz520@mail.ustc.edu.cn</a>
        </hgroup>
      </div>
    </div>
    <div class="scroll-wrap flex-col">
      <ul class="nav">
        
            <li class="waves-block waves-effect">
              <a href="/">
                <i class="icon icon-lg icon-home"></i>
                Home
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/archives">
                <i class="icon icon-lg icon-archives"></i>
                Archives
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="/tags">
                <i class="icon icon-lg icon-tags"></i>
                Tags
              </a>
            </li>
        
            <li class="waves-block waves-effect">
              <a href="https://github.com/waxin" target="_blank">
                <i class="icon icon-lg icon-github"></i>
                Github
              </a>
            </li>
        
      </ul>
    </div>
  </div>
</aside>

    <main id="main">
        <header class="top-header" id="header">
    <div class="flex-row">
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light on" id="menu-toggle">
          <i class="icon icon-lg icon-navicon"></i>
        </a>
        <div class="flex-col header-title ellipsis">总结—2019/7/27</div>
        
        <div class="search-wrap" id="search-wrap">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="back">
                <i class="icon icon-lg icon-chevron-left"></i>
            </a>
            <input type="text" id="key" class="search-input" autocomplete="off" placeholder="Search">
            <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="search">
                <i class="icon icon-lg icon-search"></i>
            </a>
        </div>
        
        
        <a href="javascript:;" class="header-icon waves-effect waves-circle waves-light" id="menuShare">
            <i class="icon icon-lg icon-share-alt"></i>
        </a>
        
    </div>
</header>
<header class="content-header post-header">

    <div class="container fade-scale">
        <h1 class="title">总结—2019/7/27</h1>
        <h5 class="subtitle">
            
                <time datetime="2019-07-28T09:42:06.000Z" itemprop="datePublished" class="page-time">
  2019-07-28
</time>


            
        </h5>
    </div>

    


</header>


<div class="container body-wrap">
    
    <aside class="post-widget">
        <nav class="post-toc-wrap post-toc-shrink" id="post-toc">
            <h4>TOC</h4>
            <ol class="post-toc"><li class="post-toc-item post-toc-level-1"><a class="post-toc-link" href="#总结-2019-7-27"><span class="post-toc-number">1.</span> <span class="post-toc-text">总结-2019/7/27</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#主要学习资料"><span class="post-toc-number">1.1.</span> <span class="post-toc-text">主要学习资料</span></a></li><li class="post-toc-item post-toc-level-2"><a class="post-toc-link" href="#内容回顾"><span class="post-toc-number">1.2.</span> <span class="post-toc-text">内容回顾</span></a><ol class="post-toc-child"><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#part1：手工构建神经网络"><span class="post-toc-number">1.2.1.</span> <span class="post-toc-text">part1：手工构建神经网络</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#part2：参数初始化"><span class="post-toc-number">1.2.2.</span> <span class="post-toc-text">part2：参数初始化</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#part3：正则化"><span class="post-toc-number">1.2.3.</span> <span class="post-toc-text">part3：正则化</span></a></li><li class="post-toc-item post-toc-level-3"><a class="post-toc-link" href="#part4：神经网络的优化"><span class="post-toc-number">1.2.4.</span> <span class="post-toc-text">part4：神经网络的优化</span></a></li></ol></li></ol></li></ol>
        </nav>
    </aside>


<article id="post-总结—2019-7-26" class="post-article article-type-post fade" itemprop="blogPost">

    <div class="post-card">
        <h1 class="post-card-title">总结—2019/7/27</h1>
        <div class="post-meta">
            <time class="post-time" title="2019-07-28 17:42:06" datetime="2019-07-28T09:42:06.000Z" itemprop="datePublished">2019-07-28</time>

            


            
<span id="busuanzi_container_page_pv" title="文章总阅读量" style="display:none">
    <i class="icon icon-eye icon-pr"></i><span id="busuanzi_value_page_pv"></span>
</span>


        </div>
        <div class="post-content" id="post-content" itemprop="postContent">
            <h1 id="总结-2019-7-27"><a href="#总结-2019-7-27" class="headerlink" title="总结-2019/7/27"></a>总结-2019/7/27</h1><p>下面主要对<strong>7-22～7-26</strong>这几天学习的一些知识进行一次回顾</p>
<a id="more"></a>
<h2 id="主要学习资料"><a href="#主要学习资料" class="headerlink" title="主要学习资料"></a>主要学习资料</h2><ul>
<li><a href="https://www.coursera.org/learn/deep-neural-network" target="_blank" rel="noopener">吴恩达coursera课程</a></li>
<li><a href="http://cs231n.stanford.edu/handouts/derivatives.pdf" target="_blank" rel="noopener">Derivatives, Backpropagation, and Vectorization</a></li>
<li><a href="https://medium.com/@prateekvishnu/xavier-and-he-normal-he-et-al-initialization-8e3d7a087528" target="_blank" rel="noopener">Xavier and He Normal (He-et-al) Initialization</a></li>
</ul>
<h2 id="内容回顾"><a href="#内容回顾" class="headerlink" title="内容回顾"></a>内容回顾</h2><h3 id="part1：手工构建神经网络"><a href="#part1：手工构建神经网络" class="headerlink" title="part1：手工构建神经网络"></a>part1：手工构建神经网络</h3><p>​    在这一周，通过课程我学习了如何利用numpy等python库来搭建一个多层的神经网络，并且对其进行训练。多层神经网络的结构如下图所示：</p>
<p align="center"><img src="/2019/07/28/总结—2019-7-26/network.png" width="300" height="200"></p>

<p align="center"><font size="2.8" color="#3333ff">图1:多层神经网络结构</font></p>

<p>​        为了构建这样一个多层的神经网络，大致需要经过以下几个步骤</p>
<ul>
<li><p>参数的初始化：例如从输入到隐藏层，我们需要的是权值矩阵以及偏置，这在一开始就需要进行初始化。一般来说，初始化所有的参数，需要先定义出各层的规模。参数的初始化对之后的训练会起到一定影响，具体会在之后说明。</p>
</li>
<li><p>前向反馈过程：有了参数以及输入，我们需要实现上述神经网络的计算过程。以图一为例（参考其网络结构，但是更改输入为纵向量），整个网络的计算过程如下：</p>
<script type="math/tex; mode=display">
Z_1 = W_1*X+b_1,\ \ \ \ \ A_1 = f_1(Z_1)\\
Z_2 = W_2*A_1+b_2, \ \ \ \ A_2 = f_2(Z_2)\\
Z_3 = W_o*A_2+b_3,\ \ \ \ \ \ \hat Y = f_3(Z_3)</script><p>其中$f$表示激活函数，常见的有$relu,  sigmoid$等，最后为了得到输出，一般会使用$sigmoid$或$softmax$，具体需要看是二分类还是多分类问题。</p>
</li>
<li><p>计算损失函数：上述神经网络最后可以计算得到预测结果$\hat y$，以二分类问题为例，对数似然损失函数如下：</p>
<script type="math/tex; mode=display">
loss = -[y*log(\hat y)\ +\ (1-y)*log(1-\hat y)]</script><p>上面展示的是对一条数据的计算过程，当进行向量化处理时需要求均值。</p>
</li>
<li><p>反向传播过程：利用反向传播，我们可以计算出损失函数对各个参数的导数，之后对各参数进行更新以降低模型在训练数据上的损失，假设训练数据的规模为$m$，并且输出层为$sigmoid$，那么图1的反向传播可以表示如下：</p>
<script type="math/tex; mode=display">
loss = -1/m*[Y*log(\hat Y)\ +\ (1-Y)*log(1-\hat Y)]\\
dZ_3 = \hat Y\ -\ Y\\
\ \\
dW_o = 1/m*dZ_3*A_2.T,\ db_3 = 1/m*np.sum(dZ_3, axis=1)\\
dA_2 = W_o.T*dZ_3,\ dZ_2 = dA_2*f_2^{'}(Z_2)\\
\ \\
dW_2 = 1/m*dZ_2*A_1.T,\ db_2 = 1/m*np.sum(dZ_2, axis=1)\\
dA_1 = W_2.T*dZ_2,\ dZ_1 = dA_1*f_1^{'}(Z_1)\\
\ \\
dW_1 = 1/m*dZ_1*A_1.T,\ db_1 = 1/m*np.sum(dZ_1, axis=1)</script></li>
<li><p>模型的组合：利用上述的几个部分，可以定义出一个神经网络模型，在训练集上进行多次迭代，不断更新参数以降低损失函数，最后得到模型的参数</p>
</li>
<li><p>预测：利用学习得到的参数以及前向反馈过程就可以对测试集进行预测</p>
</li>
</ul>
<h3 id="part2：参数初始化"><a href="#part2：参数初始化" class="headerlink" title="part2：参数初始化"></a>part2：参数初始化</h3><p>在part1中已经提到模型的参数初始化会对模型训练产生影响，下面就对参数初始化进行具体介绍。</p>
<ul>
<li><p>Zero Initialization</p>
<ul>
<li><p>将所有的权值矩阵初始化为0，假设中间层的激活函数是$relu$，输出层的激活函数为$sigmoid$</p>
<script type="math/tex; mode=display">
\begin{align}
dW_1 &= dZ_1*X.T \\
&=dA_1*f^{'}(Z_1)*X.T\\
&=W_2.T*dZ_2*f^{'}(Z_1)*X.T

\end{align}</script><p>可以看到在第一次迭代当中，$dW_1$受到$W_2$的影响结果为0，因此不会对$W_1$更新，类似的其它权值矩阵相同。对于$dW_L$:</p>
<script type="math/tex; mode=display">
\begin{align}
dW_L &=dZ_L*A_{L-1}.T\\
&=(A_L-Y)*A_{L-1}.T

\end{align}</script><p>因为中间层激活函数是$relu$，因此$dW_L$为0。如果激活函数是$tanh$，那么在第一轮迭代后会对$W_L$更新。但是由于权值矩阵中的每一行都是相同的（行向量可以看作是对输入的一个映射），根据对称性，在同一层的神经元作用相同，因此完全不推荐使用<strong>Zero Initialization</strong></p>
</li>
</ul>
</li>
<li><p>Random Initialization</p>
<ul>
<li>为了使每个神经元发挥不同的作用，我们需要保证权值矩阵中的每行向量具有区分度，因此我们可以利用Random Initialization来进行初始化。利用<code>np.random.randn</code>可以得到服从$N(\mu=0, \delta^2=1)$的特定$shape$的矩阵。但是初始化时权值矩阵的方差选择会成为比较棘手的问题，当选择过小时可能会出现梯度消失，导致训练速度过慢，当选择过大时可能会出现梯度爆炸，导致无法训练。</li>
</ul>
</li>
<li><p>HE Normal Initialization</p>
<ul>
<li>下面以中间层激活函数为$relu$的神经网络作为说明<script type="math/tex; mode=display">
\begin{align}
Z_1 &= W_1*X\\
A_1 &= relu(Z_1)\\
Z_{1_{ij}} &= \sum_{k=0}^{k=nc}W_{ik}\cdot X_{kj}
\end{align}</script>$nc$表示$X$的特征数，或者$W_1$的列数。其中假设$W_1\sim N(0, 1), X\sim N(0, 1)$，利用基础的概率轮知识可以得到$Z_1\sim N(0, nc)$，也就是说经过$W_1$后$Z_1$的方差变大了，为了尽可能优化后面的反向传播过程，这里将$W_1$的方差设置为$2/nc$，分子为2是因为采用的是$relu$函数，这种初始化的方法叫做：HE Normal Initialization</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>[ ] Q2.1:关于这里的初始化我有一些不理解的地方，比如激活函数为$relu$时为什么分子选择2，$tanh$时选择分子为1？从$Z_1$到$A_1$，由于经过了一个非线性的映射，所以输出的分布完全变化了，在这时是否还是根据的方差或者均值来选择的分子呢？要解决这个疑问，后续可能需要阅读提出He-et-al的论文。</li>
</ul>
<hr>
<h3 id="part3：正则化"><a href="#part3：正则化" class="headerlink" title="part3：正则化"></a>part3：正则化</h3><p>在机器学习的过程中，我们最终需要的是模型在测试集上取得优异的表现，但是在有些时候，模型可能会发生过拟合的情况，例如下图：</p>
<p align="center"><img src="/2019/07/28/总结—2019-7-26/overfitting.png" height="200"></p>

<p align="center"><font color="#3333ff" size="2.8">图2：Over-fitting</font></p>

<ul>
<li><p>$L_2$正则化</p>
<ul>
<li>$loss = 1/m\cdot \zeta(\hat Y,Y)+\frac{\lambda}{2m}\cdot||\theta||^2$</li>
<li>$\frac{\lambda}{2m}\cdot||\theta||^2$表示正则化项，将损失函数加上$L_2$正则化项后可以避免权值矩阵过大，以此可以降低过拟合</li>
</ul>
</li>
<li><p>Dropout</p>
<ul>
<li>dropout，即随机失活，意味着在神经网络中随机对一些神经元进行失活操作，具体的操作需要一个失活矩阵$D$来实现：<script type="math/tex; mode=display">
\begin{align}
Z_i &= W_i*A_{i-1}\\
A_i &= f(Z_i)\\
A_i &= A_i\cdot D_i/keep_prob
\end{align}</script>其中矩阵$D_i$是根据$keep_prob$来确定的0/1矩阵</li>
</ul>
</li>
</ul>
<hr>
<ul>
<li>[ ] Q3.1：$L_2$正则化有利于降低权值矩阵大小，但是权值矩阵的绝对大小对整个神经网络的效果会有什么样的影响呢？如何用数学化的形式具体说明$L_2$正则化是如何降低过拟合的呢？</li>
<li>[ ] Q3.2：在课程中，dropout是在激活层之后使用的，如果在激活层之前dropout会有什么区别呢？</li>
<li>[ ] Q3.3：dropout后保持输出的均值相同有什么作用 (利用$/keep_prob$保持均值)</li>
<li>[ ] Q3.4：dropout是如何降低过拟合的？</li>
</ul>
<hr>
<h3 id="part4：神经网络的优化"><a href="#part4：神经网络的优化" class="headerlink" title="part4：神经网络的优化"></a>part4：神经网络的优化</h3><p>Gradient descent，也就是梯度下降，是课程中一开始就使用的优化算法。根据维基百科:</p>
<blockquote>
<p>梯度下降方法基于以下的观察：如果实值函数$\displaystyle F(\mathbf {x} )$在点$\displaystyle \mathbf {a} $处<a href="https://zh.wikipedia.org/wiki/可微" target="_blank" rel="noopener">可微</a>且有定义，那么函数$\displaystyle F(\mathbf {x} )$在$\displaystyle \mathbf {a} $点沿着<a href="https://zh.wikipedia.org/wiki/梯度" target="_blank" rel="noopener">梯度</a>相反的方向 $\displaystyle -\nabla F(\mathbf {a} )$ 下降最快。</p>
</blockquote>
<p>因此，梯度下降通常也称为最速下降法。但是在数据规模很大时，梯度下降的成本非常高，因此需要进行一些转变</p>
<ul>
<li><p>Mini-batch graillent decent: 小批量梯度下降，假设$m$是整个训练集的大小，$m_{mini}$表示一个小批量数据集的大小，那么在小批量梯度下降中，算法每一次会利用$m_{mini}$条数据进行参数的更新：</p>
<script type="math/tex; mode=display">
\begin{align}
loss^t = 1/m_{mini}\cdot\zeta(\hat Y^t, Y^t)
\end{align}</script><p>$t$表示批次</p>
<p>小批量梯度下降算法每次都会优化$loss^t$，但是对于整个训练集而已，$loss$并不一定呈现出优化的状态</p>
<p align="center"><img src="/2019/07/28/总结—2019-7-26/loss.png" height="200"></p>

</li>
</ul>
<p align="center"><font color="#333fff" size="2.8">图3: 损失函数</font></p>

<ul>
<li><p>Momentum(动量) gradient decent：在梯度下降中，我们是利用当前的$dW$来更新权值矩阵，momentum梯度下降则不同，它利用指数移动加权平均的思想，通过计算一个加权的$V_{dW}$来对权值矩阵进行更新：</p>
<script type="math/tex; mode=display">
\begin{align}
V_{dW} &= 0\\
V_{dW_1} &= \beta V_{dW}+(1-\beta)dW_1\\
&\cdots\\
V_{dW_k} &= \beta V_{dW_{k-1}}+(1-\beta)dW_k
\end{align}</script></li>
<li><p>RMSprop(均方根传递)：调整$dW$大小来加速优化过程：</p>
<script type="math/tex; mode=display">
\begin{align}
S_{dW} &= 0\\
S_{dW_1} &= \beta S_{dW}+(1-\beta)dW_1^2\\
&\cdots\\
S_{dW_k} &= \beta S_{dW{k-1}}+(1-\beta)dW_{k-1}^2
\end{align}</script><p>$W$的更新如下：$W = W-\alpha\frac {dW}{\sqrt {S_{dW}}}$</p>
</li>
<li><p>Adam：Adam算法融合了上面两种算法</p>
<script type="math/tex; mode=display">
\begin{align}
&V_{dW_k} = \beta_1V_{d_{W_{k-1}}} +(1-\beta_1)dW_k\\
&S_{dW_k} = \beta_2 S_{dW{k-1}}+(1-\beta_2)dW_{k-1}^2\\

&V_{dW_kcorr}=\frac{V_{dW_k}}{1-\beta_1^t}\\
&S_{dW_kcorr}=\frac{S_{dW_k}}{1-\beta_2^t}\\
\end{align}</script><p>$W$的更新如下：$W = W-\alpha\frac {V_{dW_kcorr}}{\sqrt {S_{dW_kcorr}}}$</p>
</li>
</ul>
<hr>
<ul>
<li>[ ] Q4.1：为什么mini-batch gradient dencent可以降低整个数据集上的损失函数？</li>
<li>[ ] Q4.2：mini-batch gradient dencent的噪声是由哪些因素决定的？这些因素又是怎样影响到噪声大小的？</li>
<li>[ ] Q4.3：上面提到的动量、RMSprop以及Adam加速优化的原因？</li>
</ul>

        </div>

        <blockquote class="post-copyright">
    
    <div class="content">
        
<span class="post-time">
    Last updated: <time datetime="2019-07-28T10:03:43.086Z" itemprop="dateUpdated">2019-07-28 18:03:43</time>
</span><br>


        
        Stay hungry, stay foolish
        
    </div>
    
    <footer>
        <a href="http://yoursite.com">
            <img src="/img/avatar.jpg" alt="Alephn">
            Alephn
        </a>
    </footer>
</blockquote>

        
<div class="page-reward">
    <a id="rewardBtn" href="javascript:;" class="page-reward-btn waves-effect waves-circle waves-light">赏</a>
</div>



        <div class="post-footer">
            
	<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/machien-learning/">machien learning</a></li></ul>


            
<div class="page-share-wrap">
    

<div class="page-share" id="pageShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://yoursite.com/2019/07/28/总结—2019-7-26/&title=《总结—2019/7/27》 — Alephn's Blog&pic=http://yoursite.com/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://yoursite.com/2019/07/28/总结—2019-7-26/&title=《总结—2019/7/27》 — Alephn's Blog&source=总结-2019/7/27下面主要对7-22～7-26这几天学习的一些知识进行一次回顾" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://yoursite.com/2019/07/28/总结—2019-7-26/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《总结—2019/7/27》 — Alephn's Blog&url=http://yoursite.com/2019/07/28/总结—2019-7-26/&via=http://yoursite.com" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://yoursite.com/2019/07/28/总结—2019-7-26/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>



    <a href="javascript:;" id="shareFab" class="page-share-fab waves-effect waves-circle">
        <i class="icon icon-share-alt icon-lg"></i>
    </a>
</div>



        </div>
    </div>

    
<nav class="post-nav flex-row flex-justify-between flex-row-reverse">
  

  
    <div class="waves-block waves-effect next">
      <a href="/2019/06/29/numpy向量化操作/" id="post-next" class="post-nav-link">
        <div class="tips">Next <i class="icon icon-angle-right icon-lg icon-pl"></i></div>
        <h4 class="title">numpy向量化操作</h4>
      </a>
    </div>
  
</nav>



    


<section class="comments" id="comments">
    <div id="disqus_thread"></div>
    <script>
    var disqus_shortname = 'true';
    lazyScripts.push('//' + disqus_shortname + '.disqus.com/embed.js')
    </script>
    <noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
</section>
















</article>

<div id="reward" class="page-modal reward-lay">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <h3 class="reward-title">
        <i class="icon icon-quote-left"></i>
        Thank You~
        <i class="icon icon-quote-right"></i>
    </h3>
    <div class="reward-content">
        
        <div class="reward-code">
            <img id="rewardCode" src="/img/wechat.jpg" alt="打赏二维码">
        </div>
        
        <label class="reward-toggle">
            <input id="rewardToggle" type="checkbox" class="reward-toggle-check" data-wechat="/img/wechat.jpg" data-alipay="/img/alipay.jpg">
            <div class="reward-toggle-ctrol">
                <span class="reward-toggle-item wechat">微信</span>
                <span class="reward-toggle-label"></span>
                <span class="reward-toggle-item alipay">支付宝</span>
            </div>
        </label>
        
    </div>
</div>



</div>

        <footer class="footer">
    <div class="top">
        
<p>
    <span id="busuanzi_container_site_uv" style="display:none">
        站点总访客数：<span id="busuanzi_value_site_uv"></span>
    </span>
    <span id="busuanzi_container_site_pv" style="display:none">
        站点总访问量：<span id="busuanzi_value_site_pv"></span>
    </span>
</p>


        <p>
            
                <span><a href="/atom.xml" target="_blank" class="rss" title="rss"><i class="icon icon-lg icon-rss"></i></a></span>
            
            <span>This blog is licensed under a <a rel="license" href="https://creativecommons.org/licenses/by/4.0/">Creative Commons Attribution 4.0 International License</a>.</span>
        </p>
    </div>
    <div class="bottom">
        <p><span>Alephn &copy; 2018 - 2019</span>
            <span>
                
                Power by <a href="http://hexo.io/" target="_blank">Hexo</a> Theme <a href="https://github.com/yscoder/hexo-theme-indigo" target="_blank">indigo</a>
            </span>
        </p>
    </div>
</footer>

    </main>
    <div class="mask" id="mask"></div>
<a href="javascript:;" id="gotop" class="waves-effect waves-circle waves-light"><span class="icon icon-lg icon-chevron-up"></span></a>



<div class="global-share" id="globalShare">
    <ul class="reset share-icons">
      <li>
        <a class="weibo share-sns" target="_blank" href="http://service.weibo.com/share/share.php?url=http://yoursite.com/2019/07/28/总结—2019-7-26/&title=《总结—2019/7/27》 — Alephn's Blog&pic=http://yoursite.com/img/avatar.jpg" data-title="微博">
          <i class="icon icon-weibo"></i>
        </a>
      </li>
      <li>
        <a class="weixin share-sns wxFab" href="javascript:;" data-title="微信">
          <i class="icon icon-weixin"></i>
        </a>
      </li>
      <li>
        <a class="qq share-sns" target="_blank" href="http://connect.qq.com/widget/shareqq/index.html?url=http://yoursite.com/2019/07/28/总结—2019-7-26/&title=《总结—2019/7/27》 — Alephn's Blog&source=总结-2019/7/27下面主要对7-22～7-26这几天学习的一些知识进行一次回顾" data-title=" QQ">
          <i class="icon icon-qq"></i>
        </a>
      </li>
      <li>
        <a class="facebook share-sns" target="_blank" href="https://www.facebook.com/sharer/sharer.php?u=http://yoursite.com/2019/07/28/总结—2019-7-26/" data-title=" Facebook">
          <i class="icon icon-facebook"></i>
        </a>
      </li>
      <li>
        <a class="twitter share-sns" target="_blank" href="https://twitter.com/intent/tweet?text=《总结—2019/7/27》 — Alephn's Blog&url=http://yoursite.com/2019/07/28/总结—2019-7-26/&via=http://yoursite.com" data-title=" Twitter">
          <i class="icon icon-twitter"></i>
        </a>
      </li>
      <li>
        <a class="google share-sns" target="_blank" href="https://plus.google.com/share?url=http://yoursite.com/2019/07/28/总结—2019-7-26/" data-title=" Google+">
          <i class="icon icon-google-plus"></i>
        </a>
      </li>
    </ul>
 </div>


<div class="page-modal wx-share" id="wxShare">
    <a class="close" href="javascript:;"><i class="icon icon-close"></i></a>
    <p>扫一扫，分享到微信</p>
    <img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAMYAAADGCAAAAACs8KCBAAACOUlEQVR42u3aS27DMAxF0ex/0+60gBvlPtINIOp6VCSGqqMBI35eL/xct+f35+v372/ev11//tgjQ4aMbRnX8iH/gHz+bmVyTOu9yZAh4xwG2UQaTDl7vRo6OBkyZMhYLk02zYO4DBkyZDwbcMkm+BVThgwZMtYMksSSglongH4pF5chQ8aGDF51//7f/9LfkCFDxlaMK3xIySy9GqZB9o9dyZAhYzSDB7gO74EEFQxzyJAhYyqjtigvw5GUuNNyaJ2NDBkyNmF0Al+nVZAeATp0GTJkjGak6WWtJMeLaHyw7EOXQ4YMGUMZvKBGvq29yQc4ZMiQcQ6jf0UjgTgtz8UJrQwZMoYy+OZqIbLW/owvoDJkyDiAQTZNAh9ZjVf1eWFOhgwZ5zCKjUOQmtZGN4KgLEOGjAMYaWMgverxkllxfRkyZBzDIMWvoM/Am46Ngwh6GjJkyNiWwbdeu/Clo2atdWTIkDGU8SGE4VJaP1inh4X6GzJkyBjBqA1b8OJap1WZjmLIkCHjBAZPaNMLHwnQaXL7NuDKkCFjNOOxslcpHU3XQb8bMmTIGMdIRyv4QfC0tjbSIUOGjNmMK3zSa19ndDXuxMqQIWMoIw2pvKDGr5U8Te38JMiQIWN3BgmyaeKaJrFpwJUhQ8aZjH5Bfz1UEZfP0iaEDBkyZIAwWhznKiW3MmTIkNHPg9Oh1bTx8La/IUOGjNEMksTyAhkPxKjLSi6UMmTIGM3ojFPUimtPtSdlyJBxAOMHN1gD8YAv418AAAAASUVORK5CYII=" alt="微信分享二维码">
</div>




    <script src="//cdn.bootcss.com/node-waves/0.7.4/waves.min.js"></script>
<script>
var BLOG = { ROOT: '/', SHARE: true, REWARD: true };


</script>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/main.min.js"></script>


<div class="search-panel" id="search-panel">
    <ul class="search-result" id="search-result"></ul>
</div>
<template id="search-tpl">
<li class="item">
    <a href="{path}" class="waves-block waves-effect">
        <div class="title ellipsis" title="{title}">{title}</div>
        <div class="flex-row flex-middle">
            <div class="tags ellipsis">
                {tags}
            </div>
            <time class="flex-col time">{date}</time>
        </div>
    </a>
</li>
</template>

<script src="//unpkg.com/hexo-theme-material-indigo@latest/js/search.min.js" async></script>



<!-- mathjax config similar to math.stackexchange -->

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML"></script>




<script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>



<script>
(function() {
    var OriginTitile = document.title, titleTime;
    document.addEventListener('visibilitychange', function() {
        if (document.hidden) {
            document.title = 'Alephn's Blog';
            clearTimeout(titleTime);
        } else {
            document.title = 'Alephn's Blog';
            titleTime = setTimeout(function() {
                document.title = OriginTitile;
            },2000);
        }
    });
})();
</script>



<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-MML-AM_CHTML"></script>
</body>
</html>
